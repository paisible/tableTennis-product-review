{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQjXsK6bjSU5",
    "outputId": "b212db5d-aafe-4d30-e5b5-68d5d050adef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 4.9MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 20.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 29.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Collecting tokenizers==0.8.1.rc2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 48.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=2773e42cfc390b918f95d61c38fe3f7abb7556313de352f6333633739b11a659\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZDhk3djhYQ1",
    "outputId": "52e4b2e4-15e8-46b9-af44-6f85631ec7d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chart_studio\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ce/330794a6b6ca4b9182c38fc69dd2a9cbff60fd49421cb8648ee5fee352dc/chart_studio-1.1.0-py3-none-any.whl (64kB)\n",
      "\r",
      "\u001b[K     |█████                           | 10kB 16.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 20kB 3.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 30kB 3.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 40kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 51kB 3.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 61kB 3.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 71kB 3.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from chart_studio) (2.23.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from chart_studio) (1.3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from chart_studio) (1.15.0)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from chart_studio) (4.4.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (2.10)\n",
      "Installing collected packages: chart-studio\n",
      "Successfully installed chart-studio-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install chart_studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwKHc6ZjtztE",
    "outputId": "a5453d8a-d74a-4c96-e8f4-4ccc25fd9fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.61)\n",
      "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from fastai) (2.2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.6.0+cu101)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (20.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.2)\n",
      "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (7.0.0)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.7.1)\n",
      "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7.0+cu101)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.18.5)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.0.2)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (7.4.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.41.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (50.3.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai) (0.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVqDyFTehjW_",
    "outputId": "78668ced-0680-4ab2-bce9-ff5dadadd2cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tU8ZPt3EkTAN"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7X_VDA0Ekga6",
    "outputId": "65d09239-392a-46fa-acc4-d1ee87aa0272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n",
      "1.15.2\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Restart runtime using 'Runtime' -> 'Restart runtime...'\n",
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cuQqKMEtjhMf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "from fastai.text import *\n",
    "from fastai.metrics import *\n",
    "from transformers import RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Go_sZgKtlRS9"
   },
   "outputs": [],
   "source": [
    "# Creating a config object to store task specific information\n",
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "        \n",
    "config = Config(\n",
    "    testing=False,\n",
    "    seed = 2020,\n",
    "    roberta_model_name='roberta-base', # can also be exchnaged with roberta-base \n",
    "    max_lr=1e-5,\n",
    "    epochs=7,\n",
    "    use_fp16=False,\n",
    "    bs=4, \n",
    "    max_seq_len=256, \n",
    "    num_labels = 3,\n",
    "    hidden_dropout_prob=.05,\n",
    "    hidden_size=768, # 1024 for roberta-large\n",
    "    start_tok = \"<s>\",\n",
    "    end_tok = \"</s>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Praq5ay-leci",
    "outputId": "18d41421-ce8b-489e-a408-71aa182e790d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Untitled0.ipynb', 'Classification_with_RoBERTa.ipynb']"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Mount Drive into Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.chdir(\"/content/drive/My Drive/DSA4\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "qh1FqwCZl3R0",
    "outputId": "279d28c4-f26e-4e44-d6f7-429d240c0edd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-cfa1c9a7-2d16-4cf6-af0f-08090550bc12\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-cfa1c9a7-2d16-4cf6-af0f-08090550bc12\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test_data.csv to test_data.csv\n",
      "Saving training_data.csv to training_data.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "hof6WpvCmKVK",
    "outputId": "65f1f335-95e4-417d-a872-ae9e390f9c45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>thread_title</th>\n",
       "      <th>reply_split</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5f686bc7b59794ca78c70902</td>\n",
       "      <td>Tenergy 05FX vs Tenergy 64FX</td>\n",
       "      <td>Hi stao, the response of the T64fx changes dep...</td>\n",
       "      <td>irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5f686bc7b59794ca78c70902</td>\n",
       "      <td>Tenergy 05FX vs Tenergy 64FX</td>\n",
       "      <td>Usually I have a Primorac Carbon and I'm offen...</td>\n",
       "      <td>irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5f686bc7b59794ca78c70902</td>\n",
       "      <td>Tenergy 05FX vs Tenergy 64FX</td>\n",
       "      <td>I used T05fx before and I really appreciate th...</td>\n",
       "      <td>comparative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  ... classification\n",
       "0  5f686bc7b59794ca78c70902  ...     irrelevant\n",
       "1  5f686bc7b59794ca78c70902  ...     irrelevant\n",
       "2  5f686bc7b59794ca78c70902  ...    comparative\n",
       "\n",
       "[3 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(io.StringIO(uploaded['training_data.csv'].decode('utf-8')))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "We5J-vZw2lmI",
    "outputId": "b05b0e17-c50e-4b9f-fd57-f9d361ce2f48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>thread_title</th>\n",
       "      <th>reply_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5f686bc8b59794ca78c70903</td>\n",
       "      <td>Butterfly Impartial XS vs 802-40 vs spinlord w...</td>\n",
       "      <td>I'm also interested.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5f686bc8b59794ca78c70903</td>\n",
       "      <td>Butterfly Impartial XS vs 802-40 vs spinlord w...</td>\n",
       "      <td>maybe TTD can start reviewing some sp rubbers?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5f686bc8b59794ca78c70903</td>\n",
       "      <td>Butterfly Impartial XS vs 802-40 vs spinlord w...</td>\n",
       "      <td>I do not know if tabletennisdaily can reiview ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  ...                                        reply_split\n",
       "0  5f686bc8b59794ca78c70903  ...                               I'm also interested.\n",
       "1  5f686bc8b59794ca78c70903  ...     maybe TTD can start reviewing some sp rubbers?\n",
       "2  5f686bc8b59794ca78c70903  ...  I do not know if tabletennisdaily can reiview ...\n",
       "\n",
       "[3 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(io.StringIO(uploaded['test_data.csv'].decode('utf-8')))\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JeYurRVSmomB"
   },
   "outputs": [],
   "source": [
    "df = df[['reply_split','classification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xyKxFL0g2uqc"
   },
   "outputs": [],
   "source": [
    "test_df = test_df[['reply_split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "2efUiGyNmx9_",
    "outputId": "98e7cb80-ceed-41b4-9879-a31c8726e79d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_split</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi stao, the response of the T64fx changes dep...</td>\n",
       "      <td>irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Usually I have a Primorac Carbon and I'm offen...</td>\n",
       "      <td>irrelevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         reply_split classification\n",
       "0  Hi stao, the response of the T64fx changes dep...     irrelevant\n",
       "1  Usually I have a Primorac Carbon and I'm offen...     irrelevant"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSJuJfpfmzg8",
    "outputId": "fd735e71-bf68-44cc-df6a-29a08246129a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reply_split       0\n",
       "classification    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlLMFvso3CLx",
    "outputId": "833b9725-dfe1-4172-ac8f-c0bb1ae341f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reply_split    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "g16aATGG7ibO"
   },
   "outputs": [],
   "source": [
    "#df = df.dropna(axis=0, how ='any')\n",
    "#test_df = test_df.dropna(axis=0, how ='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0AbETqeum-DP",
    "outputId": "3ece0586-cd50-4e18-e98a-7471cff9eb91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2176, 2) (334, 1)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZSLiSn8HnAuQ"
   },
   "outputs": [],
   "source": [
    "if config.testing: df = df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "CiXlo9u4nPyE"
   },
   "outputs": [],
   "source": [
    "feat_cols = \"reply_split\"\n",
    "label_cols = \"classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "FcIGxtHi3W4x"
   },
   "outputs": [],
   "source": [
    "feat_cols1 = \"reply_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Ef7RQuZBnTUs"
   },
   "outputs": [],
   "source": [
    "class FastAiRobertaTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around RobertaTokenizer to be compatible with fastai\"\"\"\n",
    "    def __init__(self, tokenizer: RobertaTokenizer, max_seq_len: int=128, **kwargs): \n",
    "        self._pretrained_tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len \n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self \n",
    "    def tokenizer(self, t:str) -> List[str]: \n",
    "        \"\"\"Adds Roberta bos and eos tokens and limits the maximum sequence length\"\"\" \n",
    "        return [config.start_tok] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [config.end_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "OFIjONFenWQs"
   },
   "outputs": [],
   "source": [
    "# create fastai tokenizer for roberta\n",
    "roberta_tok = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "fastai_tokenizer = Tokenizer(tok_func=FastAiRobertaTokenizer(roberta_tok, max_seq_len=config.max_seq_len), \n",
    "                             pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BESdlTy0niLB",
    "outputId": "597d3fab-6b97-4fef-d91c-64058365c8fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.tokenization_roberta.RobertaTokenizer at 0x7fcc74ecf860>"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4j4zyVZXOs9b",
    "outputId": "9ba5f7fd-83d9-48e4-88fd-7a074780cfb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0La4Fnonrbz",
    "outputId": "c56f0165-f2d4-4bd8-e0c2-16215aba67e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/content/gdrive/My Drive/DSA4/vocab.json',\n",
       " '/content/gdrive/My Drive/DSA4/merges.txt')"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = F\"/content/gdrive/My Drive/DSA4\" \n",
    "roberta_tok.save_vocabulary(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lnLHUS5GW0j5",
    "outputId": "e49d0893-dcc7-452e-cd66-aafae026f44a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Untitled0.ipynb',\n",
       " 'Classification_with_RoBERTa.ipynb',\n",
       " 'test_data.csv',\n",
       " 'training_data.csv',\n",
       " 'vocab.json',\n",
       " 'merges.txt']"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.chdir(\"/content/drive/My Drive/DSA4\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "EjL1s8s-oMRs"
   },
   "outputs": [],
   "source": [
    "# create fastai vocabulary for roberta\n",
    "path = Path()\n",
    "roberta_tok.save_vocabulary(path)\n",
    "\n",
    "with open('vocab.json', 'r') as f:\n",
    "    roberta_vocab_dict = json.load(f)\n",
    "    \n",
    "fastai_roberta_vocab = Vocab(list(roberta_vocab_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "3k5Rx6DDoXcY"
   },
   "outputs": [],
   "source": [
    "# Setting up pre-processors\n",
    "class RobertaTokenizeProcessor(TokenizeProcessor):\n",
    "    def __init__(self, tokenizer):\n",
    "         super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "class RobertaNumericalizeProcessor(NumericalizeProcessor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "def get_roberta_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n",
    "    \"\"\"\n",
    "    Constructing preprocessors for Roberta\n",
    "    We remove sos and eos tokens since we add that ourselves in the tokenizer.\n",
    "    We also use a custom vocabulary to match the numericalization with the original Roberta model.\n",
    "    \"\"\"\n",
    "    return [RobertaTokenizeProcessor(tokenizer=tokenizer), RobertaNumericalizeProcessor(vocab=vocab)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "tBjlq9UeoazB"
   },
   "outputs": [],
   "source": [
    "# Creating a Roberta specific DataBunch class\n",
    "class RobertaDataBunch(TextDataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training Roberta\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=64, val_bs:int=None, pad_idx=1,\n",
    "               pad_first=True, device:torch.device=None, no_check:bool=False, backwards:bool=False, \n",
    "               dl_tfms:Optional[Collection[Callable]]=None, **dl_kwargs) -> DataBunch:\n",
    "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "r60jkyCooeIP"
   },
   "outputs": [],
   "source": [
    "class RobertaTextList(TextList):\n",
    "    _bunch = RobertaDataBunch\n",
    "    _label_cls = TextList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "haU3W9J-ogwR"
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# loading the tokenizer and vocab processors\n",
    "processor = get_roberta_processor(tokenizer=fastai_tokenizer, vocab=fastai_roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0z2hYW0boix3",
    "outputId": "5e1d9a6b-323b-475b-cf02-fe41e9cd5489"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.RobertaTokenizeProcessor at 0x7fcc74c5e278>,\n",
       " <__main__.RobertaNumericalizeProcessor at 0x7fcc74c5e1d0>]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "mU5uU7qMolKt",
    "outputId": "bd21d6f0-7161-4490-9f5b-87794ffff592"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating our databunch \n",
    "data = RobertaTextList.from_df(df, \".\", cols=feat_cols, processor=processor) \\\n",
    "    .split_by_rand_pct(seed=config.seed) \\\n",
    "    .label_from_df(cols=label_cols,label_cls=CategoryList) \\\n",
    "    .add_test(RobertaTextList.from_df(test_df, \".\", cols=feat_cols1, processor=processor)) \\\n",
    "    .databunch(bs=config.bs, pad_first=False, pad_idx=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OwUg_jdonrP",
    "outputId": "9676bbd5-f0ed-45d5-9326-4822b547ad84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaDataBunch;\n",
       "\n",
       "Train: LabelList (1741 items)\n",
       "x: RobertaTextList\n",
       "<s> Hi Ġst ao , Ġthe Ġresponse Ġof Ġthe ĠT 64 fx Ġchanges Ġdepending Ġon Ġthe Ġthe Ġblade Ġyou 're Ġusing . </s>,<s> Usually ĠI Ġhave Ġa ĠPrim or ac ĠCarbon Ġand ĠI 'm Ġoffensive Ġplayer Ġwith Ġag ressive Ġtop Ġspin . </s>,<s> I Ġused ĠT 05 fx Ġbefore Ġand ĠI Ġreally Ġappreciate Ġthe Ġgeneral Ġfeeling Ġof Ġthe ĠT 64 fx , Ġwhich Ġis Ġmore Ġsofter Ġbut Ġfaster Ġthan Ġ05 fx . </s>,<s> On Ġthe Ġother Ġhand Ġless Ġspin Ġtoo . </s>,<s> Very Ġgood Ġfor Ġblock . </s>\n",
       "y: CategoryList\n",
       "irrelevant,irrelevant,comparative,comparative,descriptive\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (435 items)\n",
       "x: RobertaTextList\n",
       "<s> My ĠB H Ġwing Ġhas Ġa Ġlot Ġof Ġvariety Ġof Ġshots Ġpossible , Ġbut Ġat Ġthe Ġend Ġof Ġthe Ġday , Ġsofter Ġdynamic Ġrub bers , Ġor Ġslower Ġolder Ġsofter Ġrub bers Ġgive Ġme Ġmore Ġconsistency Ġin Ġlanding Ġpercentage Ġand Ġmy Ġpower Ġshots Ġon Ġthat Ġwing Ġdo Ġnot Ġlack Ġpower Ġor Ġcontrol . </s>,<s> Is k and ar </s>,<s> It Ġmay Ġsuit Ġsome Ġpunch Ġback hand Ġplayers Ġas Ġwell Ġwhere Ġthe Ġspeed Ġis Ġlikely Ġgoing Ġto Ġbe Ġmore Ġof Ġan Ġadvantage , Ġor Ġmaybe Ġeven Ġsuit Ġsome Ġback hands Ġof Ġplayers . </s>,<s> i Ġmade Ġanother Ġpage Ġin Ġthe Ġfor Ġsale Ġsection Ġdec ois Ġhang out Ġplease Ġrequest Ġthere Ġ. </s>,<s> I Ġwould Ġsuggest ĠH 3 N Ġfore hand Ġand ĠTG 2 N Ġback hand Ġon Ġa Ġwooden Ġblade Ġnot Ġtoo Ġfast Ġ( all + Ġto ĠOFF - ). T acky Ġrubber Ġdo Ġrequire Ġa Ġsomewhat Ġdifferent Ġstroke Ġto Ġnon - t acky Ġrub bers , Ġbut Ġthere 's Ġnothing Ġwrong Ġwith Ġlearning Ġhow Ġto Ġplay Ġwith Ġthem . </s>\n",
       "y: CategoryList\n",
       "irrelevant,irrelevant,irrelevant,irrelevant,irrelevant\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (334 items)\n",
       "x: RobertaTextList\n",
       "<s> I 'm Ġalso Ġinterested . </s>,<s> maybe ĠT TD Ġcan Ġstart Ġreviewing Ġsome Ġsp Ġrub bers ? </s>,<s> I Ġdo Ġnot Ġknow Ġif Ġtable ten n isd aily Ġcan Ġre iv iew Ġshort Ġp ips . </s>,<s> Think Ġthey Ġneed Ġsomeone Ġthat Ġknow Ġhow Ġto Ġplay Ġwith Ġthem . </s>,<s> I Ġthink Ġall Ġthree Ġof Ġthem Ġare Ġconsidered Ġgri ppy Ġshort Ġp ips Ġso Ġyou Ġcan Ġcreate Ġsome Ġspin Ġbut Ġthere Ġare Ġless Ġeffect Ġand Ġdeception . </s>\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ."
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Ro-VJKbJoqpZ"
   },
   "outputs": [],
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "C6_0GGbIotF4"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import RobertaModel\n",
    "\n",
    "# defining our model architecture \n",
    "class CustomRobertaModel(nn.Module):\n",
    "    def __init__(self,num_labels=3):\n",
    "        super(CustomRobertaModel,self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.roberta = RobertaModel.from_pretrained(config.roberta_model_name)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_labels) # defining final output layer\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _ , pooled_output = self.roberta(input_ids, token_type_ids, attention_mask) # \n",
    "        logits = self.classifier(pooled_output)        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "adpewieIoviF"
   },
   "outputs": [],
   "source": [
    "roberta_model = CustomRobertaModel(num_labels=config.num_labels)\n",
    "\n",
    "learn = Learner(data, roberta_model, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "i7v0hexmox9k",
    "outputId": "ab870060-0999-4b96-af6c-6b6f71d83db8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.802685</td>\n",
       "      <td>0.667555</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.549160</td>\n",
       "      <td>0.406574</td>\n",
       "      <td>0.843678</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.437588</td>\n",
       "      <td>0.336089</td>\n",
       "      <td>0.887356</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.288180</td>\n",
       "      <td>0.397193</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.164633</td>\n",
       "      <td>0.386382</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.088566</td>\n",
       "      <td>0.420515</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.087301</td>\n",
       "      <td>0.423447</td>\n",
       "      <td>0.875862</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.model.roberta.train() # setting roberta to train as it is in eval mode by default\n",
    "learn.fit_one_cycle(config.epochs, max_lr=config.max_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "V1V82K8_R0p9"
   },
   "outputs": [],
   "source": [
    "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
    "    learn.model.roberta.eval()\n",
    "    preds = learn.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "    sampler = [i for i in data.dl(ds_type).sampler]\n",
    "    reverse_sampler = np.argsort(sampler)\n",
    "    ordered_preds = preds[reverse_sampler, :]\n",
    "    pred_values = np.argmax(ordered_preds, axis=1)\n",
    "    return ordered_preds, pred_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "4T5CZQU9R8SI",
    "outputId": "fabd61d2-c03c-4f79-ca3c-2f22a418d09b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, pred_values = get_preds_as_nparray(DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulGP-5BPR_FY",
    "outputId": "794cccd5-abcb-4631-c280-d7c147475627"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8758620689655172"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy on valid\n",
    "(pred_values == data.valid_ds.y.items).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvBnKWGvS3Ga",
    "outputId": "20bd9c59-3354-4fa2-8200-9e401007aa71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomRobertaModel(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjnNiA5Gclvi",
    "outputId": "96fd9825-2ea4-4ae7-88a2-1a380778eaa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.roberta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "Bl30Nfr8PY_2",
    "outputId": "8e2788e6-4459-412b-b216-54ae95c6798a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/fastai/text/data.py:339: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  idx_min = (t != self.pad_idx).nonzero().min()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; I Ġused ĠMX - S Ġon Ġback hand Ġfor Ġtwo Ġblades , Ġone Ġis Ġtim o Ġb oll Ġspirit , Ġand Ġone Ġis Ġinner force Ġlayer Ġz lc . I 've Ġalways Ġlike Ġa Ġboosted Ġh 3 Ġneo Ġ( soft ) Ġon Ġb h , Ġ37 - 38 Ġdegree , Ġproblem Ġis Ġi Ġdont Ġlike Ġthe Ġre boost ing Ġprocess Ġ, cost ly Ġand Ġthe Ġrubber Ġdont Ġlast Ġthat</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; i Ġwas Ġthinking Ġof Ġreplacing Ġhex er Ġh d Ġon Ġmy Ġfore hand Ġwith Ġx iom Ġo 4 Ġpro Ġor Ġas ia , but Ġas Ġi 'm Ġvery Ġpleased Ġwith Ġh d Ġand Ġi Ġcould ' nt Ġget Ġany Ġconvincing Ġinfo Ġabout Ġomega 4 Ġbeing Ġmore Ġsuitable Ġfor Ġme Ġi Ġdecided Ġand Ġordered Ġa Ġnew Ġsheet Ġof Ġh d Ġ2 Ġdays Ġago ... Ġbut Ġi Ġcould Ġnot Ġresist Ġtrying</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Here 's Ġone Ġof Ġthe Ġweb Ġsites Ġthat Ġclaims Ġto Ġsell Ġ\" personal Ġrub bers \": https :// www . pro tt . v ip /\" Personal \" Ġrub bers : https :// www . pro tt . v ip / Product - List . aspx ? product type = 51 THIS Ġseems Ġto Ġbe Ġsome Ġnew Ġsort Ġof ĠDHS Ġpackaging : https :// www . pro tt .</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; That Ġcould Ġbe Ġjust Ġbecause ĠI 'm Ġso Ġused Ġto Ġplaying Ġagainst ĠT 05 .. Ġthen Ġagain ĠI Ġsee Ġballs Ġcoming Ġoff ĠR asant Ġdo Ġsome Ġvery Ġstrange Ġthings Ġat Ġtimes Ġon Ġthe Ġbounce Ġthat ĠI Ġhaven 't Ġseen Ġhappen Ġsince Ġspeed Ġglued Ġ38 mm Ġballs Ġso ĠI 'm Ġsure Ġit 's Ġmaking Ġa Ġlot Ġof Ġspin . One Ġthing Ġis Ġthat ĠR asant Ġis Ġharder Ġto Ġcontrol Ġthan</td>\n",
       "      <td>comparative</td>\n",
       "      <td>comparative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "YVQHV4yQQO1n",
    "outputId": "93c1d559-6ee1-4833-ca7b-69da0e1b7536"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, target = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPzBBlm3QThy",
    "outputId": "2efdb81f-0316-4a17-ca06-e49d15c4050d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.3904e-04, 1.4151e-03, 9.9795e-01],\n",
       "        [3.3693e-03, 3.5940e-03, 9.9304e-01],\n",
       "        [1.6394e-03, 9.0675e-04, 9.9745e-01],\n",
       "        ...,\n",
       "        [1.5220e-03, 8.5772e-04, 9.9762e-01],\n",
       "        [9.2903e-04, 7.2968e-04, 9.9834e-01],\n",
       "        [1.3856e-03, 8.9871e-04, 9.9772e-01]])"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgcFgDykQWHj",
    "outputId": "8ca12bee-40c8-4b8b-b52d-8318d6af1eb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
       "        0, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 0, 2, 2, 2, 2, 0, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 1, 2, 2, 2, 1,\n",
       "        2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 0,\n",
       "        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 2, 2, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2,\n",
       "        2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "        0, 2, 0, 0, 0, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 0, 2, 2, 2, 0, 2, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 0, 2, 1, 1,\n",
       "        0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 0,\n",
       "        2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 1, 2, 0, 1, 2, 0, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "        2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "dbPDyNdZQeFJ",
    "outputId": "9db7750d-b581-4fa3-c408-c4ce74c6ce04"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interpretations = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "2yahZcIZQoOH",
    "outputId": "e918ec98-ff24-4385-a3f3-6f0fbc41c56a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interpretations.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "JzBAXmGuQtZ0"
   },
   "outputs": [],
   "source": [
    "y_test = list(target.numpy())\n",
    "y_pred = preds.numpy()[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aDGeJvIlT8SI",
    "outputId": "60a1229e-27ed-422c-fe37-8e8717817754"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CustomRobertaModel\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Embedding            [171, 768]           38,603,520 True      \n",
       "______________________________________________________________________\n",
       "Embedding            [171, 768]           394,752    True      \n",
       "______________________________________________________________________\n",
       "Embedding            [171, 768]           768        True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 171, 171]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 3072]          2,362,368  True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           2,360,064  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 171, 171]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 3072]          2,362,368  True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           2,360,064  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 171, 171]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 3072]          2,362,368  True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           2,360,064  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 171, 171]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 3072]          2,362,368  True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           2,360,064  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 171, 171]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 3072]          2,362,368  True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           2,360,064  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 171, 171]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 3072]          2,362,368  True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           2,360,064  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 171, 171]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 3072]          2,362,368  True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           2,360,064  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 171, 171]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 3072]          2,362,368  True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           2,360,064  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 171, 171]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 3072]          2,362,368  True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           2,360,064  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 171, 171]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 3072]          2,362,368  True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           2,360,064  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 171, 171]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 3072]          2,362,368  True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           2,360,064  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 171, 171]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           590,592    True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [171, 3072]          2,362,368  True      \n",
       "______________________________________________________________________\n",
       "Linear               [171, 768]           2,360,064  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [171, 768]           1,536      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [171, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [768]                590,592    True      \n",
       "______________________________________________________________________\n",
       "Tanh                 [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [3]                  2,307      True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 124,647,939\n",
       "Total trainable params: 124,647,939\n",
       "Total non-trainable params: 0\n",
       "Optimized with 'torch.optim.adam.Adam', betas=(0.9, 0.99)\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied "
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "5z3x9w9oSP63",
    "outputId": "451d3a40-f989-495a-9653-7d5ef1e1ebc2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='41' class='' max='435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      9.43% [41/435 00:04<00:39 0.1874]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "6zUME8SNSQDx",
    "outputId": "f0eba7fb-a6b3-460a-f3c4-26fecb8f1818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 3.98E-06\n",
      "Min loss divided by 10: 2.75E-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=10,suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N0xm62sERGtk",
    "outputId": "2bdbdd78-11ee-4230-d681-094ddee85346"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category tensor(2), tensor(2), tensor([0.0020, 0.1053, 0.8927]))"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"this rubber is  very bad!\"\n",
    "learn.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zSZD6WyRGpy",
    "outputId": "c4e86818-6798-4ca7-8529-7981fe782478"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category tensor(1), tensor(1), tensor([0.0038, 0.9428, 0.0534]))"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I love this rubber its very sturdy....\"\n",
    "learn.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "sGiNQg12RGhc"
   },
   "outputs": [],
   "source": [
    "# With scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "lFzkwwXd5R91"
   },
   "outputs": [],
   "source": [
    "\n",
    "def biggernum(arr):\n",
    "    if arr[0] > arr[1]:\n",
    "        return arr[0]\n",
    "    else: \n",
    "        return arr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "mk7zxXTzsbKO"
   },
   "outputs": [],
   "source": [
    "def prediction(str): \n",
    "    pred = learn.predict(str)\n",
    "    print('The review class is: ', pred[0], ',',  'with a scale of ','{:.2f} '.format(biggernum(pred[2].numpy()) * 100), 'out of 100.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "5--RXowlbzeJ"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "H2k9HtUktPzT",
    "outputId": "109953e3-e53e-4ae4-ce21-3338fba2d28d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review class is:  irrelevant , with a scale of  0.09  out of 100.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
       "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
       "            <div id=\"eed889b4-a4ba-445a-8f01-a7d4eab1bdb0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                \n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"eed889b4-a4ba-445a-8f01-a7d4eab1bdb0\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'eed889b4-a4ba-445a-8f01-a7d4eab1bdb0',\n",
       "                        [{\"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"value=%{value}\", \"legendgroup\": \"\", \"name\": \"\", \"showlegend\": false, \"type\": \"pie\", \"values\": [0.09000000357627869, 99.91]}],\n",
       "                        {\"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Not sure what quality it is...\"}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('eed889b4-a4ba-445a-8f01-a7d4eab1bdb0');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                \n",
       "            </script>\n",
       "        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg1 = \"Not sure what quality it is...\"\n",
    "prediction(msg1)\n",
    "pred = learn.predict(msg1)\n",
    "vals = [round(biggernum(pred[2].numpy()*100), 2), round(100- biggernum(pred[2].numpy()*100),2)] \n",
    "fig = px.pie(pred, values=vals, title=msg1)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "mVuEInF3SnUp",
    "outputId": "86487870-40da-484b-8cfe-ac9035f2312d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review class is:  comparative , with a scale of  95.70  out of 100.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
       "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
       "            <div id=\"183de731-8007-48b6-8032-424508fa055a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                \n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"183de731-8007-48b6-8032-424508fa055a\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '183de731-8007-48b6-8032-424508fa055a',\n",
       "                        [{\"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"value=%{value}\", \"legendgroup\": \"\", \"name\": \"\", \"showlegend\": false, \"type\": \"pie\", \"values\": [95.69999694824219, 4.3]}],\n",
       "                        {\"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"I like hard sponge so t05 is my favourite\"}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('183de731-8007-48b6-8032-424508fa055a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                \n",
       "            </script>\n",
       "        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg2 = \"I like hard sponge so t05 is my favourite\"\n",
    "prediction(msg2)\n",
    "pred = learn.predict(msg2)\n",
    "vals = [round(biggernum(pred[2].numpy()*100), 2), round(100- biggernum(pred[2].numpy()*100),2)] \n",
    "fig = px.pie(pred, values=vals, title=msg2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "Jcjz8izfo0gP"
   },
   "outputs": [],
   "source": [
    "# Getting Predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "qCgspP0EvFEN",
    "outputId": "ca1cb60f-4252-4f6a-acb6-d77d68ec1f57"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm also interested.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maybe TTD can start reviewing some sp rubbers?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I do not know if tabletennisdaily can reiview ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         reply_split\n",
       "0                               I'm also interested.\n",
       "1     maybe TTD can start reviewing some sp rubbers?\n",
       "2  I do not know if tabletennisdaily can reiview ..."
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "7rTzJkUgvFM2",
    "outputId": "0f603062-669a-4ac8-da80-a5b882f012c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, test_pred_values = get_preds_as_nparray(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xuN9oVpZvFBR",
    "outputId": "8193026b-5500-4d56-b2c3-be94ac974287"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, ..., 2, 2, 2, 2])"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "DhPMNSTNvLkY"
   },
   "outputs": [],
   "source": [
    "test_df[\"predicted_class\"] = test_pred_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "tNFVno-1vLwK",
    "outputId": "15053c6f-cb18-4048-9409-53eb98ee4c11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_split</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm also interested.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maybe TTD can start reviewing some sp rubbers?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I do not know if tabletennisdaily can reiview ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Think they need someone that know how to play ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think all three of them are considered gripp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>802 40 is not a rubber with inbuilt glue effec...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>So the two latter is proably a bit faster?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I also think 802 40 is hardest, or atleast fee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Try google and you will find alot.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Or ask at oaak tabletennis forum.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         reply_split  predicted_class\n",
       "0                               I'm also interested.                2\n",
       "1     maybe TTD can start reviewing some sp rubbers?                2\n",
       "2  I do not know if tabletennisdaily can reiview ...                2\n",
       "3  Think they need someone that know how to play ...                2\n",
       "4  I think all three of them are considered gripp...                0\n",
       "5  802 40 is not a rubber with inbuilt glue effec...                2\n",
       "6         So the two latter is proably a bit faster?                2\n",
       "7  I also think 802 40 is hardest, or atleast fee...                0\n",
       "8                 Try google and you will find alot.                2\n",
       "9                  Or ask at oaak tabletennis forum.                2"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "IAXtphgzvL4h",
    "outputId": "58a0d60e-bb73-403d-fd75-68f8e6de2617"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_split</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Easy to search and compares all other rubbers ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>So it seems that...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Tenergy64 (2.1) = 67g to 68g</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Tenergy64 (1.9) = 63g</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Tenergy05(2.1) = 70g</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Tenergy05(1.9) = 66g to 68g</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>There is about 4g different for 2.1 and 1.9 sh...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>So after cutting it out, I assume, the differe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>3g for both side is equal to 6g.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>I suppose 6g makes a SIGNIFICANT difference fo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reply_split  predicted_class\n",
       "324  Easy to search and compares all other rubbers ...                2\n",
       "325                                So it seems that...                2\n",
       "326                       Tenergy64 (2.1) = 67g to 68g                2\n",
       "327                              Tenergy64 (1.9) = 63g                2\n",
       "328                               Tenergy05(2.1) = 70g                2\n",
       "329                        Tenergy05(1.9) = 66g to 68g                2\n",
       "330  There is about 4g different for 2.1 and 1.9 sh...                2\n",
       "331  So after cutting it out, I assume, the differe...                2\n",
       "332                   3g for both side is equal to 6g.                2\n",
       "333  I suppose 6g makes a SIGNIFICANT difference fo...                2"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "3BqfWRgbo-Cq"
   },
   "outputs": [],
   "source": [
    "# Saving/Loading the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "JWiFYlzkpCCe"
   },
   "outputs": [],
   "source": [
    "def save_model(learner, file_name):\n",
    "    st = learner.model.state_dict()\n",
    "    torch.save(st, file_name) # will save model in current dir # backend is pickle \n",
    "\n",
    "def load_model(learner, file_name):\n",
    "    st = torch.load(file_name)\n",
    "    learner.model.load_state_dict(st)\n",
    "\n",
    "# monkey patching Learner methods to save and load model file\n",
    "Learner.save_model = save_model\n",
    "Learner.load_model = load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1zsdPKvpDxW",
    "outputId": "f06e4efb-7984-4824-edff-910ccc5d3f84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.save_model>"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "QTlSxdxVpvss"
   },
   "outputs": [],
   "source": [
    "path = 'drive/My Drive/DSA4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "RQWrIqjvpF5l"
   },
   "outputs": [],
   "source": [
    "learn.save_model('mymodel.path1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "uEpZ1BxepNKF"
   },
   "outputs": [],
   "source": [
    "learn.load_model('mymodel.path1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "CpX7bhM6bRLb"
   },
   "outputs": [],
   "source": [
    "test_df = test_df[['reply_split', \"predicted_class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "j0r26jsIbRT8",
    "outputId": "76830ac5-1b09-43be-bf22-1bbc3e233a6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_split</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm also interested.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maybe TTD can start reviewing some sp rubbers?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I do not know if tabletennisdaily can reiview ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Think they need someone that know how to play ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think all three of them are considered gripp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>802 40 is not a rubber with inbuilt glue effec...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>So the two latter is proably a bit faster?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I also think 802 40 is hardest, or atleast fee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Try google and you will find alot.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Or ask at oaak tabletennis forum.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         reply_split  predicted_class\n",
       "0                               I'm also interested.                2\n",
       "1     maybe TTD can start reviewing some sp rubbers?                2\n",
       "2  I do not know if tabletennisdaily can reiview ...                2\n",
       "3  Think they need someone that know how to play ...                2\n",
       "4  I think all three of them are considered gripp...                0\n",
       "5  802 40 is not a rubber with inbuilt glue effec...                2\n",
       "6         So the two latter is proably a bit faster?                2\n",
       "7  I also think 802 40 is hardest, or atleast fee...                0\n",
       "8                 Try google and you will find alot.                2\n",
       "9                  Or ask at oaak tabletennis forum.                2"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ex4HUcwCXrvb",
    "outputId": "a3a6beac-ec41-4c76-8490-ce6c989576b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1])"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.predicted_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "Wsf4qSV5QBkF"
   },
   "outputs": [],
   "source": [
    "test_df.to_csv(\"test_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FiWgpLTiQIsh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Classification_with_RoBERTa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
