{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to generate wordclouds for different brands using different modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from common import connectMongo\n",
    "from common import getData\n",
    "from viz import createWordcloud\n",
    "from common import cleanData\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connectMongo.connect_mongo('forums','ooakForum')\n",
    "import re \n",
    "\n",
    "patterns = {'Butterfly Tenergy 05':\"[tT]energy[-\\s]?05\\s?[^Ff]?[^Xx]?\",\n",
    "            'Butterfly Tenergy 05 FX':\"[tT]energy[-\\s]?05[-\\s]?[Ff][Xx]\",\n",
    "            'Butterfly Tenergy 25':\"[tT]energy[-\\s]?25\",\n",
    "            'Butterfly Tenergy 64':\"[tT]energy[-\\s]?64\",\n",
    "            'Butterfly Tenergy 80':\"[tT]energy[-\\s]?80\",\n",
    "            'Donic Baracuda':\"[Bb]aracuda\",\n",
    "            'Andro Rasant':\"[Rr]asant\",  \n",
    "            'DHS Hurricane 2': \"H[-\\s]?2|Hurricane[-\\s]?2\",\n",
    "            'DHS Hurricane 3': \"H[-\\s]?2|Hurricane[-\\s]?3\",\n",
    "            'DHS Hurricane 8': \"H[-\\s]?2|Hurricane[-\\s]?8\",\n",
    "            'Tibhar-Evolution-EL-P': 'EL[-\\s]?P',\n",
    "            'Tibhar-Evolution-EL-S': 'EL[-\\s]?S',\n",
    "            'Tibhar-Evolution-EL-P': 'MX[-\\s]?P',\n",
    "            'Tibhar-Evolution-EL-P': 'MX[-\\s]?S',\n",
    "            ''\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_cloud(rubber_name,pattern,searchfor, stopwords):\n",
    "    \n",
    "    print('start generating wordcloud - {}'.format(rubber_name))\n",
    "    regex_or = re.compile(pattern, re.IGNORECASE)\n",
    "    regex_or_result = conn.find({\"title\":regex_or},{\"title\":1,\"replies.clean_text\":1})\n",
    "    tmp = getData.generate_df_from_result(regex_or_result)\n",
    "    \n",
    "    print(tmp.shape)\n",
    "    \n",
    "    df_s = tmp.copy()\n",
    "    df_s['reply_split'] = df_s.reply.apply(getData.tokenize_sent)  # df_s.reply.apply(tokenize_sent)\n",
    "    df_s = df_s.explode('reply_split')\n",
    "    df_s = df_s.drop('reply', axis=1)\n",
    "    df_s = df_s.loc[df_s['reply_split'].notnull(),:]\n",
    "    \n",
    "    df_s.reset_index(inplace=True)\n",
    "#    searchfor = ['[tT]energy]', '[tT]05','[Ff][Xx]']\n",
    "    df1 = df_s[df_s.reply_split.str.contains('|'.join(searchfor))]\n",
    "    \n",
    "    print(df1.shape)\n",
    "    \n",
    "    data_col = 'reply_split'\n",
    "    clean_df1 = cleanData.preprocess_news(df1,data_col,lowercase=True)\n",
    "    clean_df1 = cleanData.remove_dash(clean_df1)\n",
    "    string_df1 = ' '.join(clean_df1)    \n",
    "    \n",
    "    rubber_name_with_dash = rubber_name.replace(' ','-')\n",
    "    \n",
    "    ## Red Wordcloud\n",
    "    createWordcloud.produce_wordcloud_graphics(string_df1,\n",
    "                                               stopwords,\n",
    "                                               '../../output/wordcloud/{}-red.png'.format(rubber_name_with_dash),\n",
    "                                               color='red')\n",
    "    ## Black Wordcloud\n",
    "    createWordcloud.produce_wordcloud_graphics(string_df1,\n",
    "                                               stopwords,\n",
    "                                               '../../output/wordcloud/{}-black.png'.format(rubber_name_with_dash),\n",
    "                                               color='black')\n",
    "    \n",
    "    print('exported successfully - {}'.format(rubber_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating wordcloud - Yasaka-Rakza-7-Soft\n",
      "(64, 3)\n",
      "(51, 4)\n",
      "exported successfully - Yasaka-Rakza-7-Soft\n"
     ]
    }
   ],
   "source": [
    "rubber_name = 'Yasaka-Rakza-7-Soft'\n",
    "pattern = \"Rakza[-\\s]?7[-\\s]?[Ss]oft|r7s\"\n",
    "searchfor = ['[Rr]akza','[Rr]7']\n",
    "stopwords = cleanData.get_stopwords_list()\n",
    "stopwords.extend(['T05FX','T05','rubber','t05fx','t05',\"t05fx'\",\"t05\",'05fx',                     \n",
    "'t05','nt','would','much','t05fx','play','get','feel','...','one',\n",
    "                      'use','tenergy','used','the','tried','using','think','t64',\n",
    "                  'ball','spin','speed','playing','played','player',\n",
    "                  'good','better','new','05 fx','fx','t80','80','T 80',\n",
    "                     've','also','viewtopic','www','http','blade','sponge','com','php'\n",
    "                  'tabletennis','pro','version','el','told','thing','rakza','r7','soft','r7s'])\n",
    "\n",
    "generate_word_cloud(rubber_name,pattern,searchfor, stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenergy 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_or = re.compile(patterns['Tenergy 05'], re.IGNORECASE)\n",
    "regex_or_result = conn.find({\"title\":regex_or},{\"title\":1,\"replies.clean_text\":1})\n",
    "tmp = getData.generate_df_from_result(regex_or_result)\n",
    "df_s = tmp.copy()\n",
    "df_s['reply_split'] = df_s.reply.apply(getData.tokenize_sent)  # df_s.reply.apply(tokenize_sent)\n",
    "df_s = df_s.explode('reply_split')\n",
    "df_s = df_s.drop('reply', axis=1)\n",
    "df_s = df_s.loc[df_s['reply_split'].notnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s.reset_index(inplace=True)\n",
    "searchfor = ['[tT]energy]', '[tT]05']\n",
    "df1 = df_s[df_s.reply_split.str.contains('|'.join(searchfor))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenergy 05 FX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_or = re.compile(patterns['Tenergy 05 FX'], re.IGNORECASE)\n",
    "regex_or_result = conn.find({\"title\":regex_or},{\"title\":1,\"replies.clean_text\":1})\n",
    "tmp = getData.generate_df_from_result(regex_or_result)\n",
    "df_s = tmp.copy()\n",
    "df_s['reply_split'] = df_s.reply.apply(getData.tokenize_sent)  # df_s.reply.apply(tokenize_sent)\n",
    "df_s = df_s.explode('reply_split')\n",
    "df_s = df_s.drop('reply', axis=1)\n",
    "df_s = df_s.loc[df_s['reply_split'].notnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s.reset_index(inplace=True)\n",
    "searchfor = ['[tT]energy]', '[tT]05','[Ff][Xx]']\n",
    "df1 = df_s[df_s.reply_split.str.contains('|'.join(searchfor))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "54+8+17+8+36+23+15+21+363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>thread_title</th>\n",
       "      <th>reply_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5f6c28d14272aba9ab77574c</td>\n",
       "      <td>Tenergy 05 fx for chopping/looping</td>\n",
       "      <td>What level are you playing at?My nooby rump is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>5f6c28d14272aba9ab77574c</td>\n",
       "      <td>Tenergy 05 fx for chopping/looping</td>\n",
       "      <td>The 05 fx has a softer sponge than the 05 so t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>5f6c28d14272aba9ab77574c</td>\n",
       "      <td>Tenergy 05 fx for chopping/looping</td>\n",
       "      <td>I guess I'll go with 05 fx/80 because of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>5f6c28d14272aba9ab77574c</td>\n",
       "      <td>Tenergy 05 fx for chopping/looping</td>\n",
       "      <td>I do not think that 05FX is much different fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>5f6c28d14272aba9ab77574c</td>\n",
       "      <td>Tenergy 05 fx for chopping/looping</td>\n",
       "      <td>I agree with Omut that the 05fx and Aurus Soft...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                        id                        thread_title  \\\n",
       "2       1  5f6c28d14272aba9ab77574c  Tenergy 05 fx for chopping/looping   \n",
       "12      1  5f6c28d14272aba9ab77574c  Tenergy 05 fx for chopping/looping   \n",
       "26      1  5f6c28d14272aba9ab77574c  Tenergy 05 fx for chopping/looping   \n",
       "29      1  5f6c28d14272aba9ab77574c  Tenergy 05 fx for chopping/looping   \n",
       "32      1  5f6c28d14272aba9ab77574c  Tenergy 05 fx for chopping/looping   \n",
       "\n",
       "                                          reply_split  \n",
       "2   What level are you playing at?My nooby rump is...  \n",
       "12  The 05 fx has a softer sponge than the 05 so t...  \n",
       "26  I guess I'll go with 05 fx/80 because of the s...  \n",
       "29  I do not think that 05FX is much different fro...  \n",
       "32  I agree with Omut that the 05fx and Aurus Soft...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baracuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_or = re.compile(patterns['Baracuda'], re.IGNORECASE)\n",
    "regex_or_result = conn.find({\"title\":regex_or},{\"title\":1,\"replies.clean_text\":1})\n",
    "tmp = getData.generate_df_from_result(regex_or_result)\n",
    "df_s = tmp.copy()\n",
    "df_s['reply_split'] = df_s.reply.apply(getData.tokenize_sent)\n",
    "df_s = df_s.explode('reply_split')\n",
    "df_s = df_s.drop('reply', axis=1)\n",
    "df_s_tmp = df_s.loc[df_s['reply_split'].notnull(),:]\n",
    "df_s_tmp.reset_index(inplace=True)\n",
    "searchfor = ['[bB]aracuda']\n",
    "df2 = df_s_tmp[df_s_tmp.reply_split.str.contains('|'.join(searchfor))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import cleanData\n",
    "data_col = 'reply_split'\n",
    "clean_df1 = cleanData.preprocess_news(df1,data_col,lowercase=True)\n",
    "clean_df2 = cleanData.preprocess_news(df2,data_col,lowercase=True)\n",
    "\n",
    "clean_df1 = cleanData.remove_dash(clean_df1)\n",
    "clean_df2 = cleanData.remove_dash(clean_df2)\n",
    "\n",
    "string_df1 = ' '.join(clean_df1)    \n",
    "string_df2 = ' '.join(clean_df2)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "stop_words = cleanData.get_stopwords_list()\n",
    "t05_stopwords = stop_words\n",
    "t05_stopwords.extend(['T05FX','T05','rubber','t05fx','t05',\"t05fx'\",\"t05 '\",                     \n",
    "'t05','nt','would','much','t05fx','play','get','feel','...','one',\n",
    "                      'use','tenergy','used','the','tried','using','think','t64','ball','spin','speed','playing','played','player','good','better','new'])\n",
    "print(len(t05_stopwords))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "baracuda_stopwords = stop_words\n",
    "baracuda_stopwords.extend(['T05FX','T05','rubber','t05fx','t05',\"t05fx'\",\"t05 '\",                     \n",
    "'t05','nt','would','much','t05fx','play','get','feel','...','one','quite','also',\n",
    "                      'use','tenergy','used','the','tried','using','think','baracuda','spin','speed','playing','played','player','good','better'])\n",
    "print(len(baracuda_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tenergy 05 FX Red/Black Wordcloud\n",
    "createWordcloud.produce_wordcloud_graphics(string_df1,t05_stopwords,'../../output/wordcloud/Butterfly-Tenergy-05-FX-red.png',color='red')\n",
    "createWordcloud.produce_wordcloud_graphics(string_df1,t05_stopwords,'../../output/wordcloud/Butterfly-Tenergy-05-FX-black.png',color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baracuda Black Wordcloud\n",
    "createWordcloud.produce_wordcloud_graphics(string_df2,baracuda_stopwords,'../../output/wordcloud/Baracuda.png',color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--Andro-Rasant\n",
    "--Butterfly-Tenergy-05\n",
    "--Butterfly-Tenergy-05-FX\n",
    "--Butterfly-Tenergy-25\n",
    "--Butterfly-Tenergy-64\n",
    "--Butterfly-Tenergy-80\n",
    "--Chinese-rubbers\n",
    "---DHS-Hurricane-2\n",
    "--DHS-Hurricane-3\n",
    "--DHS-Hurricane-8\n",
    "--Donic-Baracuda\n",
    "--Donic-Baracuda-Big-Slam\n",
    "--Donic-Bluefire-JP-03\n",
    "--Donic-Vario-Big-Slam\n",
    "--Galaxy-Mercury-II\n",
    "--Galaxy-Moon\n",
    "--Tibhar-Evolution-EL-P\n",
    "--Tibhar-Evolution-EL-S\n",
    "--Tibhar-Evolution-MX-P\n",
    "--Tibhar-Evolution-MX-S\n",
    "Yasaka-Rakza-7\n",
    "Yasaka-Rakza-7-Soft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
